{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3543e2dc",
   "metadata": {},
   "source": [
    "Code de calcul des statistiques pour article TALN 2025 (Barletta, Ponton)\n",
    "Prends en entrée un fichier csv ayant cette structure (généré à partir des annotations au format UIMA CAS 1.0 et les codes merge_uimacas puis uimacas_stats_unify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559d7050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d389a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul mentions, chaines, anaphores et singletons ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b194edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a8fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1506b84b",
   "metadata": {},
   "source": [
    "Calcul de la densité : \n",
    "nb des mentions par texte / nb de tokens par texte\n",
    "Filtrage des mentions contenues dans des mentions plus larges pour ne pas biaser le calcul (ex ((son) chat) - \"son\" éliminé du calcul des mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b482566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FRANCAIS ***\n",
      "Densité moyenne CE1 :  22.119334468721494\n",
      "Densité moyenne CE2 :  21.17301431824066\n",
      "Densité moyenne :  21.64617439348108\n",
      "*** ITA ***\n",
      "Densité moyenne CE1 :  22.123998442875674\n",
      "Densité moyenne CE2 :  21.631055782214172\n",
      "Densité moyenne :  21.87752711254493\n"
     ]
    }
   ],
   "source": [
    "##combien de tokens dans les mentions sum tot et sum par niveau\n",
    "def remove_contained_spans(df, suffix):\n",
    "    kept_spans = []\n",
    "    removed_spans = []\n",
    "\n",
    "    # Group by 'Source' to process spans within the same source separately\n",
    "    for source, group in df.groupby('Source'):\n",
    "        # Sort spans within each group\n",
    "        group_sorted = group.sort_values(by=['begin', 'end'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "        # Track kept spans and max end value\n",
    "        filtered_spans = []\n",
    "        max_end = -1\n",
    "        \n",
    "        for _, row in group_sorted.iterrows():\n",
    "            begin, end = row['begin'], row['end']\n",
    "\n",
    "            # If the span is contained within a larger span, remove it\n",
    "            if end <= max_end:\n",
    "                removed_spans.append(row)\n",
    "            else:\n",
    "                filtered_spans.append(row)\n",
    "                max_end = max(max_end, end)  # Update max_end\n",
    "        \n",
    "        kept_spans.extend(filtered_spans)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_filtered = pd.DataFrame(kept_spans)\n",
    "    df_removed = pd.DataFrame(removed_spans)\n",
    "\n",
    "    # Save removed spans to CSV\n",
    "    df_removed.to_csv('removed_spans'+suffix+'.csv', index=False)\n",
    "\n",
    "    return df_filtered  # Return the cleaned DataFrame\n",
    "\n",
    "\n",
    "#CALCUL DE LA DENSITE référentielle : nb tokens mentions / nb tokens texte \n",
    "def calcul_density(fr, toks_df, filename) : \n",
    "    # Filter out empty values in 'Text' column (Source)\n",
    "    df_fr_filtered = fr[fr['Source'] != '']\n",
    "\n",
    "    # Group by 'Text' and count occurrences\n",
    "    df_counts = df_fr_filtered.groupby('Source').size().reset_index(name='Mentions')\n",
    "    df_counts['Source'] = df_counts['Source'].str[:-4]\n",
    "\n",
    "    #mentions_sum = df_counts['Mentions'].sum()\n",
    "\n",
    "    # Rename 'old_name' to 'new_name'\n",
    "    df_counts.rename(columns={'Source': 'texte'}, inplace=True)\n",
    "    #print(df_counts)\n",
    "\n",
    "    fr_toks = pd.read_csv(toks_df)\n",
    "    fr_toks = fr_toks[['texte', 'nbTokNoPunct']]\n",
    "    #corpus_francais_v3\n",
    "    # Merge on the 'text' column\n",
    "    df_merged = df_counts.merge(fr_toks, on='texte', how='inner')  # 'inner' ensures only matching \"text\" values remain\n",
    "\n",
    "    #print(df_merged)\n",
    "\n",
    "    #densité = ratio nb ER / nb tokens (no punct)\n",
    "    df_merged['density'] = df_merged['Mentions'] / df_merged['nbTokNoPunct']*100\n",
    "\n",
    "    df_merged.to_csv(filename, index=False)\n",
    "\n",
    "    level=\"CE1\"\n",
    "    df_CE1 = df_merged[df_merged['texte'].str.contains(level, case=False, na=False)]\n",
    "    level=\"CE2\"\n",
    "    df_CE2 = df_merged[df_merged['texte'].str.contains(level, case=False, na=False)]\n",
    "\n",
    "    moy_density_CE1 = df_CE1['density'].mean()\n",
    "    moy_density_CE2 = df_CE2['density'].mean()\n",
    "    moy_density = df_merged['density'].mean()\n",
    "    \n",
    "    return moy_density, moy_density_CE1, moy_density_CE2\n",
    "\n",
    "###MAIN FR\n",
    "fr = pd.read_csv(\"./annotations_francais/toutes_mentions_corpus_detail_interdistance_fr.csv\")\n",
    "fr = fr.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])\n",
    "\n",
    "toks_df = \"./annotations_francais/corpus_francais_v3.csv\"\n",
    "res_fr = \"./annotations_francais/density_fr.csv\"\n",
    "fr_filtered = remove_contained_spans(fr, \"fr\")\n",
    "\n",
    "moy_density, moy_density_CE1, moy_density_CE2 = calcul_density(fr_filtered, toks_df, res_fr)\n",
    "\n",
    "print(\"*** FRANCAIS ***\")\n",
    "\n",
    "print(\"Densité moyenne CE1 : \", moy_density_CE1)\n",
    "print(\"Densité moyenne CE2 : \", moy_density_CE2)\n",
    "print(\"Densité moyenne : \", moy_density)\n",
    "\n",
    "# ####MAIN ITA\n",
    "ita = pd.read_csv(\"./annotations_italien/toutes_mentions_corpus_detail_interdistance_ita.csv\")\n",
    "ita = ita.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])\n",
    "\n",
    "toks_df = (\"./annotations_italien/corpus_italien.csv\")\n",
    "res_ita = \"./annotations_italien/density_ita.csv\"\n",
    "ita_filtered = remove_contained_spans(ita, \"ita\")\n",
    "\n",
    "moy_density, moy_density_CE1, moy_density_CE2 = calcul_density(ita_filtered, toks_df, res_ita)\n",
    "\n",
    "print(\"*** ITA ***\")\n",
    "\n",
    "print(\"Densité moyenne CE1 : \", moy_density_CE1)\n",
    "print(\"Densité moyenne CE2 : \", moy_density_CE2)\n",
    "print(\"Densité moyenne : \", moy_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127f583",
   "metadata": {},
   "source": [
    "calcul du coefficient de stabilité de Perret \n",
    "- filtra le catene meno lunghe di 3 (solo catene vere e proprie nel conto)\n",
    "- esclude la prima menzione della catena nel caso in cui sia una menzione nominale indefinita (un gatto)\n",
    "- da come risultato la stabilité di perret e l'instabilité di Rousier-Vercruyssen e Landragin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7f53a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  Unnamed: 0.1  begin  end              mention       tag  \\\n",
      "0              0             0     18   37  un petit chat blanc       cat   \n",
      "1              1             1     38   41                  qui       cat   \n",
      "2              2             2     77   90        le petit chat       cat   \n",
      "3              3             3    107  109                   il       cat   \n",
      "4              4             4    183  202  le petit chat blanc       cat   \n",
      "...          ...           ...    ...  ...                  ...       ...   \n",
      "3136        3136            10    165  168                  vit      wolf   \n",
      "3137        3137            11    266  273              le loup      wolf   \n",
      "3138        3138            12    232  251  son ami le chasseur      ext1   \n",
      "3139        3139            13    259  261                   il      ext1   \n",
      "3140        3140            14    298  301                  ils  cat+ext1   \n",
      "\n",
      "                                 POS  \\\n",
      "0      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "1                           ['PRON']   \n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "3                           ['PRON']   \n",
      "4      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "...                              ...   \n",
      "3136                        ['VERB']   \n",
      "3137                 ['DET', 'NOUN']   \n",
      "3138  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "3139                        ['PRON']   \n",
      "3140                        ['PRON']   \n",
      "\n",
      "                                                  morph  mentionLen  \\\n",
      "0     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           4   \n",
      "1                                      ['PronType=Rel']           1   \n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "3                  ['Gender=Masc|Number=Sing|Person=3']           1   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           4   \n",
      "...                                                 ...         ...   \n",
      "3136  ['Mood=Ind|Number=Sing|Person=3|Tense=Pres|Ver...           1   \n",
      "3137  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "3138  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...           4   \n",
      "3139               ['Gender=Masc|Number=Sing|Person=3']           1   \n",
      "3140               ['Gender=Masc|Number=Plur|Person=3']           1   \n",
      "\n",
      "                               POSno  \\\n",
      "0      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "1                           ['PRON']   \n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "3                           ['PRON']   \n",
      "4      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "...                              ...   \n",
      "3136                        ['VERB']   \n",
      "3137                 ['DET', 'NOUN']   \n",
      "3138  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "3139                        ['PRON']   \n",
      "3140                        ['PRON']   \n",
      "\n",
      "                                           morphNoPunct  mentionLenNoPunct  \\\n",
      "0     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  4   \n",
      "1                                      ['PronType=Rel']                  1   \n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "3                  ['Gender=Masc|Number=Sing|Person=3']                  1   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  4   \n",
      "...                                                 ...                ...   \n",
      "3136  ['Mood=Ind|Number=Sing|Person=3|Tense=Pres|Ver...                  1   \n",
      "3137  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "3138  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...                  4   \n",
      "3139               ['Gender=Masc|Number=Sing|Person=3']                  1   \n",
      "3140               ['Gender=Masc|Number=Plur|Person=3']                  1   \n",
      "\n",
      "      tokenBegin  tokenEnd  distance  tag_occurrences  interdistance  \\\n",
      "0            4.0       7.0         4                1              0   \n",
      "1            8.0       8.0         0                2              0   \n",
      "2           16.0      18.0         7                3              7   \n",
      "3           22.0      22.0         3                4              3   \n",
      "4           38.0      41.0         4                5             15   \n",
      "...          ...       ...       ...              ...            ...   \n",
      "3136        31.0      31.0         3                2             12   \n",
      "3137        49.0      50.0         1                3             17   \n",
      "3138        42.0      45.0         0                1              0   \n",
      "3139        47.0      47.0         1                2              1   \n",
      "3140        56.0      56.0         5                1              0   \n",
      "\n",
      "                                   Source  \n",
      "0     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "1     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "2     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "3     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "4     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "...                                   ...  \n",
      "3136   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3137   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3138   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3139   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3140   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "\n",
      "[3104 rows x 18 columns]\n",
      "      Unnamed: 0  Unnamed: 0.1  begin  end              mention   tag  \\\n",
      "0              0             0     18   37  un petit chat blanc   cat   \n",
      "2              2             2     77   90        le petit chat   cat   \n",
      "4              4             4    183  202  le petit chat blanc   cat   \n",
      "5              5             5    220  233        Le petit chat   cat   \n",
      "6              6             6    114  121              un loup  wolf   \n",
      "...          ...           ...    ...  ...                  ...   ...   \n",
      "3127        3127             1     49   59           une chatte   cat   \n",
      "3129        3129             3    120  132         cette chatte   cat   \n",
      "3135        3135             9     89   96              un loup  wolf   \n",
      "3137        3137            11    266  273              le loup  wolf   \n",
      "3138        3138            12    232  251  son ami le chasseur  ext1   \n",
      "\n",
      "                                 POS  \\\n",
      "0      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "4      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "5             ['DET', 'ADJ', 'NOUN']   \n",
      "6                    ['DET', 'NOUN']   \n",
      "...                              ...   \n",
      "3127                 ['DET', 'NOUN']   \n",
      "3129                 ['DET', 'NOUN']   \n",
      "3135                 ['DET', 'NOUN']   \n",
      "3137                 ['DET', 'NOUN']   \n",
      "3138  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "\n",
      "                                                  morph  mentionLen  \\\n",
      "0     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           4   \n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           4   \n",
      "5     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "6     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "...                                                 ...         ...   \n",
      "3127  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...           2   \n",
      "3129  ['Gender=Fem|Number=Sing|PronType=Dem', 'Gende...           2   \n",
      "3135  ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "3137  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "3138  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...           4   \n",
      "\n",
      "                               POSno  \\\n",
      "0      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "4      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "5             ['DET', 'ADJ', 'NOUN']   \n",
      "6                    ['DET', 'NOUN']   \n",
      "...                              ...   \n",
      "3127                 ['DET', 'NOUN']   \n",
      "3129                 ['DET', 'NOUN']   \n",
      "3135                 ['DET', 'NOUN']   \n",
      "3137                 ['DET', 'NOUN']   \n",
      "3138  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "\n",
      "                                           morphNoPunct  mentionLenNoPunct  \\\n",
      "0     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  4   \n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  4   \n",
      "5     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "6     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "...                                                 ...                ...   \n",
      "3127  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...                  2   \n",
      "3129  ['Gender=Fem|Number=Sing|PronType=Dem', 'Gende...                  2   \n",
      "3135  ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "3137  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "3138  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...                  4   \n",
      "\n",
      "      tokenBegin  tokenEnd  distance  tag_occurrences  interdistance  \\\n",
      "0            4.0       7.0         4                1              0   \n",
      "2           16.0      18.0         7                3              7   \n",
      "4           38.0      41.0         4                5             15   \n",
      "5           45.0      47.0         3                6              3   \n",
      "6           24.0      25.0         1                1              0   \n",
      "...          ...       ...       ...              ...            ...   \n",
      "3127        10.0      11.0         7                2              7   \n",
      "3129        23.0      24.0         3                4              3   \n",
      "3135        17.0      18.0         5                1              0   \n",
      "3137        49.0      50.0         1                3             17   \n",
      "3138        42.0      45.0         0                1              0   \n",
      "\n",
      "                                   Source  \n",
      "0     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "2     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "4     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "5     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "6     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "...                                   ...  \n",
      "3127   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3129   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3135   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3137   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3138   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "\n",
      "[1351 rows x 18 columns]\n",
      "      Unnamed: 0  Unnamed: 0.1  begin  end                   mention  \\\n",
      "0              0             0     18   37       un petit chat blanc   \n",
      "6              6             6    114  121                   un loup   \n",
      "11            11             0      7   15                  un robot   \n",
      "18            18             7     72   79                   un loup   \n",
      "23            23             0     18   25                   un chat   \n",
      "...          ...           ...    ...  ...                       ...   \n",
      "3041        3041            30    281  297          une petite fille   \n",
      "3080        3080            23    165  189  toutes sortes d' animaux   \n",
      "3088        3088            31    278  292            un loup féroce   \n",
      "3102        3102             0     18   39     une chatte abandonnée   \n",
      "3135        3135             9     89   96                   un loup   \n",
      "\n",
      "                      tag                             POS  \\\n",
      "0                     cat   ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "6                    wolf                 ['DET', 'NOUN']   \n",
      "11                  robot                 ['DET', 'NOUN']   \n",
      "18                   wolf                 ['DET', 'NOUN']   \n",
      "23                    cat                 ['DET', 'NOUN']   \n",
      "...                   ...                             ...   \n",
      "3041                 ext1          ['DET', 'ADJ', 'NOUN']   \n",
      "3080  ext1+ext2+ext3+ext4  ['DET', 'NOUN', 'ADP', 'NOUN']   \n",
      "3088                 wolf          ['DET', 'NOUN', 'ADJ']   \n",
      "3102                  cat         ['DET', 'NOUN', 'VERB']   \n",
      "3135                 wolf                 ['DET', 'NOUN']   \n",
      "\n",
      "                                                  morph  mentionLen  \\\n",
      "0     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           4   \n",
      "6     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "11    ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "18    ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "23    ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "...                                                 ...         ...   \n",
      "3041  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...           3   \n",
      "3080  ['Definite=Ind|Gender=Fem|Number=Plur|PronType...           4   \n",
      "3088  ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "3102  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...           3   \n",
      "3135  ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "\n",
      "                               POSno  \\\n",
      "0      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "6                    ['DET', 'NOUN']   \n",
      "11                   ['DET', 'NOUN']   \n",
      "18                   ['DET', 'NOUN']   \n",
      "23                   ['DET', 'NOUN']   \n",
      "...                              ...   \n",
      "3041          ['DET', 'ADJ', 'NOUN']   \n",
      "3080  ['DET', 'NOUN', 'ADP', 'NOUN']   \n",
      "3088          ['DET', 'NOUN', 'ADJ']   \n",
      "3102         ['DET', 'NOUN', 'VERB']   \n",
      "3135                 ['DET', 'NOUN']   \n",
      "\n",
      "                                           morphNoPunct  mentionLenNoPunct  \\\n",
      "0     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  4   \n",
      "6     ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "11    ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "18    ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "23    ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "...                                                 ...                ...   \n",
      "3041  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...                  3   \n",
      "3080  ['Definite=Ind|Gender=Fem|Number=Plur|PronType...                  4   \n",
      "3088  ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "3102  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...                  3   \n",
      "3135  ['Definite=Ind|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "\n",
      "      tokenBegin  tokenEnd  distance  tag_occurrences  interdistance  \\\n",
      "0            4.0       7.0         4                1              0   \n",
      "6           24.0      25.0         1                1              0   \n",
      "11           2.0       3.0         2                1              0   \n",
      "18          16.0      17.0         2                1              0   \n",
      "23           4.0       5.0         4                1              0   \n",
      "...          ...       ...       ...              ...            ...   \n",
      "3041        52.0      54.0        10                1              0   \n",
      "3080        32.0      35.0         2                1              0   \n",
      "3088        49.0      51.0         1                1              0   \n",
      "3102         4.0       6.0         4                1              0   \n",
      "3135        17.0      18.0         5                1              0   \n",
      "\n",
      "                                   Source  \n",
      "0     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "6     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "11    NORM-EC-CE1-2015-102-D1-S217-V1.csv  \n",
      "18    NORM-EC-CE1-2015-102-D1-S217-V1.csv  \n",
      "23    NORM-EC-CE1-2015-104-D1-S824-V1.csv  \n",
      "...                                   ...  \n",
      "3041  NORM-EC-CE2-2016-96-D1-S1926-V1.csv  \n",
      "3080   NORM-EC-CE2-2016-98-D1-S816-V1.csv  \n",
      "3088   NORM-EC-CE2-2016-98-D1-S816-V1.csv  \n",
      "3102   NORM-EC-CE2-2016-98-D1-S834-V1.csv  \n",
      "3135   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "\n",
      "[234 rows x 18 columns]\n",
      "      Unnamed: 0  Unnamed: 0.1  begin  end              mention   tag  \\\n",
      "2              2             2     77   90        le petit chat   cat   \n",
      "4              4             4    183  202  le petit chat blanc   cat   \n",
      "5              5             5    220  233        le petit chat   cat   \n",
      "8              8             8    139  146              le loup  wolf   \n",
      "10            10            10    237  244              le loup  wolf   \n",
      "...          ...           ...    ...  ...                  ...   ...   \n",
      "3126        3126             0      0   17    la chatte magique   cat   \n",
      "3127        3127             1     49   59           une chatte   cat   \n",
      "3129        3129             3    120  132         cette chatte   cat   \n",
      "3137        3137            11    266  273              le loup  wolf   \n",
      "3138        3138            12    232  251  son ami le chasseur  ext1   \n",
      "\n",
      "                                 POS  \\\n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "4      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "5             ['DET', 'ADJ', 'NOUN']   \n",
      "8                    ['DET', 'NOUN']   \n",
      "10                   ['DET', 'NOUN']   \n",
      "...                              ...   \n",
      "3126          ['DET', 'NOUN', 'ADJ']   \n",
      "3127                 ['DET', 'NOUN']   \n",
      "3129                 ['DET', 'NOUN']   \n",
      "3137                 ['DET', 'NOUN']   \n",
      "3138  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "\n",
      "                                                  morph  mentionLen  \\\n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           4   \n",
      "5     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "8     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "10    ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "...                                                 ...         ...   \n",
      "3126  ['Definite=Def|Gender=Fem|Number=Sing|PronType...           3   \n",
      "3127  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...           2   \n",
      "3129  ['Gender=Fem|Number=Sing|PronType=Dem', 'Gende...           2   \n",
      "3137  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "3138  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...           4   \n",
      "\n",
      "                               POSno  \\\n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "4      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "5             ['DET', 'ADJ', 'NOUN']   \n",
      "8                    ['DET', 'NOUN']   \n",
      "10                   ['DET', 'NOUN']   \n",
      "...                              ...   \n",
      "3126          ['DET', 'NOUN', 'ADJ']   \n",
      "3127                 ['DET', 'NOUN']   \n",
      "3129                 ['DET', 'NOUN']   \n",
      "3137                 ['DET', 'NOUN']   \n",
      "3138  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "\n",
      "                                           morphNoPunct  mentionLenNoPunct  \\\n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  4   \n",
      "5     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "8     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "10    ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "...                                                 ...                ...   \n",
      "3126  ['Definite=Def|Gender=Fem|Number=Sing|PronType...                  3   \n",
      "3127  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...                  2   \n",
      "3129  ['Gender=Fem|Number=Sing|PronType=Dem', 'Gende...                  2   \n",
      "3137  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "3138  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...                  4   \n",
      "\n",
      "      tokenBegin  tokenEnd  distance  tag_occurrences  interdistance  \\\n",
      "2           16.0      18.0         7                3              7   \n",
      "4           38.0      41.0         4                5             15   \n",
      "5           45.0      47.0         3                6              3   \n",
      "8           29.0      30.0         2                3              2   \n",
      "10          49.0      50.0         1                5             15   \n",
      "...          ...       ...       ...              ...            ...   \n",
      "3126         0.0       2.0         0                1              0   \n",
      "3127        10.0      11.0         7                2              7   \n",
      "3129        23.0      24.0         3                4              3   \n",
      "3137        49.0      50.0         1                3             17   \n",
      "3138        42.0      45.0         0                1              0   \n",
      "\n",
      "                                   Source  \n",
      "2     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "4     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "5     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "8     NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "10    NORM-EC-CE1-2015-102-D1-S212-V1.csv  \n",
      "...                                   ...  \n",
      "3126   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3127   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3129   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3137   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "3138   NORM-EC-CE2-2016-98-D1-S940-V1.csv  \n",
      "\n",
      "[1117 rows x 18 columns]\n",
      "                                  Source    tag  nominalMent  unique  \\\n",
      "0    NORM-EC-CE1-2015-102-D1-S212-V1.csv    cat            3       2   \n",
      "1    NORM-EC-CE1-2015-102-D1-S212-V1.csv   wolf            2       1   \n",
      "2    NORM-EC-CE1-2015-102-D1-S217-V1.csv  robot            2       1   \n",
      "3    NORM-EC-CE1-2015-104-D1-S824-V1.csv    cat            1       1   \n",
      "4    NORM-EC-CE1-2015-104-D1-S824-V1.csv   ext1            1       1   \n",
      "..                                   ...    ...          ...     ...   \n",
      "370   NORM-EC-CE2-2016-98-D1-S834-V1.csv  robot            1       1   \n",
      "371   NORM-EC-CE2-2016-98-D1-S936-V1.csv    cat            3       2   \n",
      "372   NORM-EC-CE2-2016-98-D1-S940-V1.csv    cat            3       3   \n",
      "373   NORM-EC-CE2-2016-98-D1-S940-V1.csv   ext1            1       1   \n",
      "374   NORM-EC-CE2-2016-98-D1-S940-V1.csv   wolf            1       1   \n",
      "\n",
      "     stability  instability  \n",
      "0          1.5    66.666667  \n",
      "1          2.0    50.000000  \n",
      "2          2.0    50.000000  \n",
      "3          1.0   100.000000  \n",
      "4          1.0   100.000000  \n",
      "..         ...          ...  \n",
      "370        1.0   100.000000  \n",
      "371        1.5    66.666667  \n",
      "372        1.0   100.000000  \n",
      "373        1.0   100.000000  \n",
      "374        1.0   100.000000  \n",
      "\n",
      "[375 rows x 6 columns]\n",
      "['Nb of nominal anaphora tot.: 1351\\n', 'Nb of nominal anaphora no Indef tot.: 1117\\n', 'Stability CE1 : 1.690670859538784\\n', 'Stability CE2 : 2.0816358024691355\\n', 'Stability CE1-CE2 : 1.9158666666666664\\n', 'Instability CE1 : 77.22072476789458\\n', 'Instability CE2 : 67.60519380311045\\n', 'Instability CE1-CE2 : 71.68217893217891\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_28552/3355923136.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sn_mentions['mention'] = sn_mentions['mention'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "file = \"./annotations_francais/toutes_mentions_corpus_detail_interdistance_fr.csv\"\n",
    "#file = \"./annotations_italien/toutes_mentions_corpus_detail_interdistance_ita.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "\n",
    "#filtrer singletons et anaphores et inclure seulement chaines 3+\n",
    "# Count occurrences of each tag in each Source\n",
    "tag_counts = df.groupby(['tag', 'Source']).size().reset_index(name='count')\n",
    "\n",
    "# Keep only tags appearing more than twice in a Source\n",
    "valid_tags = tag_counts[tag_counts['count'] > 2]['tag']\n",
    "\n",
    "# Filter the original DataFrame\n",
    "filtered_df = df[df['tag'].isin(valid_tags)]\n",
    "\n",
    "print(filtered_df)\n",
    "\n",
    "\n",
    "# Filtering rows where 'Text' column contains \"NOUN\" --> mentions nominales (SN)\n",
    "# erreurs possibles\n",
    "sn_mentions = df[df['POSno'].str.contains('NOUN', na=False)]\n",
    "\n",
    "print(sn_mentions)\n",
    "\n",
    "#lower case to avoid upper/lower case bias\n",
    "sn_mentions['mention'] = sn_mentions['mention'].str.lower()\n",
    "\n",
    "# #TODO add filter out IndSN mentions\n",
    "# # Group by 'Source' and 'tag', then compute the required metrics\n",
    "# result = sn_mentions.groupby(['Source', 'tag']).agg(\n",
    "#     nominalMent=('mention', 'count'),  # Count total mentions\n",
    "#     unique=('mention', pd.Series.nunique)  # Count unique mentions\n",
    "# ).reset_index()\n",
    "\n",
    "# # Add the new column with the formula\n",
    "# result['stability'] = result['nominalMent'] / result['unique']\n",
    "# result['instability'] = result['unique'] / result['nominalMent'] * 100\n",
    "\n",
    "# print(result)\n",
    "# instability_moy = result['instability'].mean()\n",
    "\n",
    "# #moyenne de l'instabilité par niveau puis total\n",
    "# level=\"CE1\"\n",
    "# df_CE1 = result[result['Source'].str.contains(level, case=False, na=False)]\n",
    "# ce1_instability_moy = df_CE1['instability'].mean()\n",
    "\n",
    "# level=\"CE2\"\n",
    "# df_CE2 = result[result['Source'].str.contains(level, case=False, na=False)]\n",
    "# ce2_instability_moy = df_CE2['instability'].mean()\n",
    "\n",
    "\n",
    "###calcul du vrai coefficient de Perret : \n",
    "# si la première mention de la chaine est un SN indéfini, exclure du décompte\n",
    "\n",
    "#group mentions by tag\n",
    "#if tag_occurrences is 1 and first POSno is DET and 1st part of morphNoPunct is equal to Definite=Ind\n",
    "\n",
    "sn_indef = sn_mentions[\n",
    "    (sn_mentions['tag_occurrences'] == 1) &\n",
    "    (sn_mentions['POSno'].str.startswith(\"['DET\")) &\n",
    "    (sn_mentions['morphNoPunct'].str.startswith(\"['Definite=Ind\"))\n",
    "]\n",
    "\n",
    "print(sn_indef)\n",
    "\n",
    "# mentions filtrées : seulement mentions nominales, exclus les première mentions de chaine SN indéfini\n",
    "sn_no_indef = sn_mentions[\n",
    "    ~(\n",
    "      (sn_mentions['tag_occurrences'] == 1) &\n",
    "      (sn_mentions['POSno'].str.startswith(\"['DET\")) &\n",
    "      (sn_mentions['morphNoPunct'].str.startswith(\"['Definite=Ind\"))\n",
    "     )\n",
    "]\n",
    "\n",
    "print(sn_no_indef)\n",
    "\n",
    "\n",
    "#calcul du coefficient\n",
    "result = sn_no_indef.groupby(['Source', 'tag']).agg(\n",
    "    nominalMent=('mention', 'count'),  # Count total mentions\n",
    "    unique=('mention', pd.Series.nunique)  # Count unique mentions\n",
    ").reset_index()\n",
    "\n",
    "# Add the new column with the formula\n",
    "result['stability'] = result['nominalMent'] / result['unique']\n",
    "result['instability'] = result['unique'] / result['nominalMent'] * 100\n",
    "\n",
    "print(result)\n",
    "instability_moy = result['instability'].mean()\n",
    "stability_moy = result['stability'].mean()\n",
    "\n",
    "#moyenne de l'instabilité par niveau puis total\n",
    "level=\"CE1\"\n",
    "df_CE1 = result[result['Source'].str.contains(level, case=False, na=False)]\n",
    "ce1_instability_moy = df_CE1['instability'].mean()\n",
    "ce1_stability_moy = df_CE1['stability'].mean()\n",
    "\n",
    "level=\"CE2\"\n",
    "df_CE2 = result[result['Source'].str.contains(level, case=False, na=False)]\n",
    "ce2_instability_moy = df_CE2['instability'].mean()\n",
    "ce2_stability_moy = df_CE2['stability'].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "txt = \"./instability_fr.txt\"\n",
    "with open(txt, \"w\") as file:\n",
    "    file.write(f\"Nb of nominal anaphora tot.: {len(sn_mentions)}\\n\")\n",
    "    file.write(f\"Nb of nominal anaphora no Indef tot.: {len(sn_no_indef)}\\n\")\n",
    "    \n",
    "    file.write(f\"Stability CE1 : {ce1_stability_moy}\\n\")\n",
    "    file.write(f\"Stability CE2 : {ce2_stability_moy}\\n\")\n",
    "    file.write(f\"Stability CE1-CE2 : {stability_moy}\\n\")\n",
    "    \n",
    "    file.write(f\"Instability CE1 : {ce1_instability_moy}\\n\")\n",
    "    file.write(f\"Instability CE2 : {ce2_instability_moy}\\n\")\n",
    "    file.write(f\"Instability CE1-CE2 : {instability_moy}\\n\")\n",
    "    \n",
    "with open(txt, \"r\") as res:\n",
    "    print(res.readlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60c5bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  Unnamed: 0.1  begin  end              mention   tag  \\\n",
      "0              2             2     77   90        le petit chat   cat   \n",
      "1              4             4    183  202  le petit chat blanc   cat   \n",
      "2              5             5    220  233        le petit chat   cat   \n",
      "3              8             8    139  146              le loup  wolf   \n",
      "4             10            10    237  244              le loup  wolf   \n",
      "...          ...           ...    ...  ...                  ...   ...   \n",
      "1112        3126             0      0   17    la chatte magique   cat   \n",
      "1113        3127             1     49   59           une chatte   cat   \n",
      "1114        3129             3    120  132         cette chatte   cat   \n",
      "1115        3137            11    266  273              le loup  wolf   \n",
      "1116        3138            12    232  251  son ami le chasseur  ext1   \n",
      "\n",
      "                                 POS  \\\n",
      "0             ['DET', 'ADJ', 'NOUN']   \n",
      "1      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "3                    ['DET', 'NOUN']   \n",
      "4                    ['DET', 'NOUN']   \n",
      "...                              ...   \n",
      "1112          ['DET', 'NOUN', 'ADJ']   \n",
      "1113                 ['DET', 'NOUN']   \n",
      "1114                 ['DET', 'NOUN']   \n",
      "1115                 ['DET', 'NOUN']   \n",
      "1116  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "\n",
      "                                                  morph  mentionLen  \\\n",
      "0     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "1     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           4   \n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           3   \n",
      "3     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "...                                                 ...         ...   \n",
      "1112  ['Definite=Def|Gender=Fem|Number=Sing|PronType...           3   \n",
      "1113  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...           2   \n",
      "1114  ['Gender=Fem|Number=Sing|PronType=Dem', 'Gende...           2   \n",
      "1115  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...           2   \n",
      "1116  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...           4   \n",
      "\n",
      "                               POSno  \\\n",
      "0             ['DET', 'ADJ', 'NOUN']   \n",
      "1      ['DET', 'ADJ', 'NOUN', 'ADJ']   \n",
      "2             ['DET', 'ADJ', 'NOUN']   \n",
      "3                    ['DET', 'NOUN']   \n",
      "4                    ['DET', 'NOUN']   \n",
      "...                              ...   \n",
      "1112          ['DET', 'NOUN', 'ADJ']   \n",
      "1113                 ['DET', 'NOUN']   \n",
      "1114                 ['DET', 'NOUN']   \n",
      "1115                 ['DET', 'NOUN']   \n",
      "1116  ['DET', 'NOUN', 'DET', 'NOUN']   \n",
      "\n",
      "                                           morphNoPunct  mentionLenNoPunct  \\\n",
      "0     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "1     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  4   \n",
      "2     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  3   \n",
      "3     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "4     ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "...                                                 ...                ...   \n",
      "1112  ['Definite=Def|Gender=Fem|Number=Sing|PronType...                  3   \n",
      "1113  ['Definite=Ind|Gender=Fem|Number=Sing|PronType...                  2   \n",
      "1114  ['Gender=Fem|Number=Sing|PronType=Dem', 'Gende...                  2   \n",
      "1115  ['Definite=Def|Gender=Masc|Number=Sing|PronTyp...                  2   \n",
      "1116  ['Number=Sing|Poss=Yes', 'Gender=Masc|Number=S...                  4   \n",
      "\n",
      "      tokenBegin  tokenEnd  distance  tag_occurrences  interdistance  \\\n",
      "0           16.0      18.0         7                3              7   \n",
      "1           38.0      41.0         4                5             15   \n",
      "2           45.0      47.0         3                6              3   \n",
      "3           29.0      30.0         2                3              2   \n",
      "4           49.0      50.0         1                5             15   \n",
      "...          ...       ...       ...              ...            ...   \n",
      "1112         0.0       2.0         0                1              0   \n",
      "1113        10.0      11.0         7                2              7   \n",
      "1114        23.0      24.0         3                4              3   \n",
      "1115        49.0      50.0         1                3             17   \n",
      "1116        42.0      45.0         0                1              0   \n",
      "\n",
      "                                   Source  stability  instability  \n",
      "0     NORM-EC-CE1-2015-102-D1-S212-V1.csv        1.5    66.666667  \n",
      "1     NORM-EC-CE1-2015-102-D1-S212-V1.csv        1.5    66.666667  \n",
      "2     NORM-EC-CE1-2015-102-D1-S212-V1.csv        1.5    66.666667  \n",
      "3     NORM-EC-CE1-2015-102-D1-S212-V1.csv        2.0    50.000000  \n",
      "4     NORM-EC-CE1-2015-102-D1-S212-V1.csv        2.0    50.000000  \n",
      "...                                   ...        ...          ...  \n",
      "1112   NORM-EC-CE2-2016-98-D1-S940-V1.csv        1.0   100.000000  \n",
      "1113   NORM-EC-CE2-2016-98-D1-S940-V1.csv        1.0   100.000000  \n",
      "1114   NORM-EC-CE2-2016-98-D1-S940-V1.csv        1.0   100.000000  \n",
      "1115   NORM-EC-CE2-2016-98-D1-S940-V1.csv        1.0   100.000000  \n",
      "1116   NORM-EC-CE2-2016-98-D1-S940-V1.csv        1.0   100.000000  \n",
      "\n",
      "[1117 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_28552/2476417353.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sn_mentions['mention'] = sn_mentions['mention'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the DataFrame `df` loaded\n",
    "\n",
    "# Filtering rows for SN mentions\n",
    "sn_mentions = df[df['POSno'].str.contains('NOUN', na=False)]\n",
    "sn_mentions['mention'] = sn_mentions['mention'].str.lower()\n",
    "\n",
    "# Filtering out SN mentions with 'IndSN' (if needed)\n",
    "sn_no_indef = sn_mentions[~(\n",
    "    (sn_mentions['tag_occurrences'] == 1) & \n",
    "    (sn_mentions['POSno'].str.startswith(\"['DET\")) & \n",
    "    (sn_mentions['morphNoPunct'].str.startswith(\"['Definite=Ind\"))\n",
    ")]\n",
    "\n",
    "# Grouping by 'Source' and 'tag', then calculate the stability and instability for each group\n",
    "result = sn_no_indef.groupby(['Source', 'tag']).agg(\n",
    "    nominalMent=('mention', 'count'),  # Total mentions\n",
    "    unique=('mention', pd.Series.nunique)  # Count unique mentions\n",
    ").reset_index()\n",
    "\n",
    "# Add columns for stability and instability\n",
    "result['stability'] = result['nominalMent'] / result['unique']\n",
    "result['instability'] = result['unique'] / result['nominalMent'] * 100\n",
    "\n",
    "# Merge the computed 'stability' and 'instability' back into the original DataFrame\n",
    "df_with_stability = sn_no_indef.merge(result[['Source', 'tag', 'stability', 'instability']], \n",
    "                                      on=['Source', 'tag'], \n",
    "                                      how='left')\n",
    "\n",
    "# Display the result (DataFrame with stability and instability for each row)\n",
    "print(df_with_stability)\n",
    "\n",
    "# Optionally, save the result to a CSV if you need\n",
    "df_with_stability.to_csv('df_with_stability_instability.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54347148",
   "metadata": {},
   "source": [
    "Creazione dell'Excel con le tipologie di menzione ATTENZIONE va corretto manualmente per evitare il tasso di errore su alcune categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./annotations_francais/toutes_mentions_corpus_detail_interdistance_fr.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Assuming df is already defined\n",
    "remaining_df = df.copy()  # Copy the original dataframe to filter progressively\n",
    "\n",
    "# Extract each category and update remaining_df\n",
    "sn_def = remaining_df[remaining_df['POSno'].str.contains('NOUN', na=False) & remaining_df['morphNoPunct'].str.startswith(\"['Definite=Def\", na=False)]\n",
    "remaining_df = remaining_df.drop(sn_def.index)  # Remove classified elements\n",
    "\n",
    "sn_ind = remaining_df[remaining_df['POSno'].str.contains('NOUN', na=False) & remaining_df['morphNoPunct'].str.startswith(\"['Definite=Ind\", na=False)]\n",
    "remaining_df = remaining_df.drop(sn_ind.index)\n",
    "\n",
    "#TODO add criteria\n",
    "sn_poss = remaining_df[remaining_df['POSno'].str.contains('DET', na=False) & remaining_df['morphNoPunct'].str.contains(\"Poss=Yes\", na=False)\n",
    "                       & remaining_df['POSno'].str.contains('NOUN', na=False)]\n",
    "remaining_df = remaining_df.drop(sn_poss.index)\n",
    "\n",
    "verb = remaining_df[remaining_df['POSno'].str.contains('VERB|AUX', na=False) & ~remaining_df['POSno'].str.contains('NOUN', na=False)]\n",
    "remaining_df = remaining_df.drop(verb.index)\n",
    "\n",
    "pron = remaining_df[remaining_df['POSno'] == \"['PRON']\"]\n",
    "remaining_df = remaining_df.drop(pron.index)\n",
    "\n",
    "propn = df[(df['POSno'] == \"['PROPN']\") | (df['POSno'] == \"['PROPN', 'PROPN']\")]\n",
    "remaining_df = remaining_df.drop(propn.index)\n",
    "\n",
    "det_poss = remaining_df[(remaining_df['POSno'] == \"['DET']\") & remaining_df['morphNoPunct'].str.contains('Poss=Yes', na=False)]\n",
    "remaining_df = remaining_df.drop(det_poss.index)\n",
    "\n",
    "sn_dem = remaining_df[(remaining_df['POSno'].str.startswith(\"['DET'\", na=False)) & remaining_df['morphNoPunct'].str.contains('PronType=Dem', na=False)]\n",
    "remaining_df = remaining_df.drop(sn_dem.index)\n",
    "\n",
    "num = remaining_df[(remaining_df['POSno'].str.startswith(\"['NUM'\", na=False))]\n",
    "remaining_df = remaining_df.drop(num.index)\n",
    "\n",
    "sn_no_det = remaining_df[remaining_df['POSno'].str.contains('NOUN', na=False) & ~remaining_df['POSno'].str.startswith(\"['DET\", na=False)]\n",
    "remaining_df = remaining_df.drop(sn_no_det.index)\n",
    "\n",
    "\n",
    "# Collect remaining elements into \"autre\"\n",
    "autre = remaining_df.copy()\n",
    "\n",
    "# Write to Excel\n",
    "with pd.ExcelWriter('fr_types.xlsx') as writer:\n",
    "    sn_def.to_excel(writer, sheet_name='sn_def', index=False)\n",
    "    sn_ind.to_excel(writer, sheet_name='sn_indef', index=False)\n",
    "    sn_poss.to_excel(writer, sheet_name='sn_poss', index=False)\n",
    "    verb.to_excel(writer, sheet_name='verb', index=False)\n",
    "    pron.to_excel(writer, sheet_name='pron', index=False)\n",
    "    propn.to_excel(writer, sheet_name='propn', index=False)\n",
    "    det_poss.to_excel(writer, sheet_name='det_poss', index=False)\n",
    "    sn_dem.to_excel(writer, sheet_name='sn_dem', index=False)\n",
    "    sn_no_det.to_excel(writer, sheet_name='sn_no_det', index=False)\n",
    "    num.to_excel(writer, sheet_name='numerals', index=False)\n",
    "    autre.to_excel(writer, sheet_name='autre', index=False)  # Write remaining elements\n",
    "    \n",
    "   \n",
    "print(\"Excel file 'fr_types.xlsx' created successfully!\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09407e0a",
   "metadata": {},
   "source": [
    "Versione adattata per l'italiano : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = \"./annotations_francais/toutes_mentions_corpus_detail_interdistance_fr.csv\"\n",
    "file = \"./annotations_italien/toutes_mentions_corpus_detail_interdistance_ita.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Assuming df is already defined\n",
    "remaining_df = df.copy()  # Copy the original dataframe to filter progressively\n",
    "\n",
    "sn_poss = remaining_df[remaining_df['POSno'].str.contains('DET', na=False) & remaining_df['morphNoPunct'].str.contains(\"Poss=Yes\", na=False)\n",
    "                       & remaining_df['POSno'].str.contains('NOUN', na=False)]\n",
    "remaining_df = remaining_df.drop(sn_poss.index)\n",
    "\n",
    "\n",
    "propn = remaining_df[(remaining_df['POSno'] == \"['PROPN']\") | (remaining_df['POSno'] == \"['PROPN', 'PROPN']\") | remaining_df['POSno'].str.startswith(\"['PROPN'\") ]\n",
    "remaining_df = remaining_df.drop(propn.index)\n",
    "\n",
    "# Extract each category and update remaining_df\n",
    "sn_def = remaining_df[remaining_df['POSno'].str.contains('NOUN', na=False) & remaining_df['morphNoPunct'].str.startswith(\"['Definite=Def\", na=False)]\n",
    "remaining_df = remaining_df.drop(sn_def.index)  # Remove classified elements\n",
    "\n",
    "sn_ind = remaining_df[remaining_df['POSno'].str.contains('NOUN', na=False) & remaining_df['morphNoPunct'].str.startswith(\"['Definite=Ind\", na=False)]\n",
    "remaining_df = remaining_df.drop(sn_ind.index)\n",
    "\n",
    "#TODO add criteria\n",
    "verb = remaining_df[remaining_df['POSno'].str.contains('VERB|AUX', na=False)]\n",
    "remaining_df = remaining_df.drop(verb.index)\n",
    "\n",
    "sn_dem = remaining_df[(remaining_df['POSno'].str.startswith(\"['DET'\", na=False)) & remaining_df['morphNoPunct'].str.contains('PronType=Dem', na=False)]\n",
    "remaining_df = remaining_df.drop(sn_dem.index)\n",
    "\n",
    "\n",
    "pron_clit_formes = \"lo|la|gli|le|li|gli|glie|mi|ti|ci|si|ne|lui|loro|che\"\n",
    "# Correct condition syntax\n",
    "pron = remaining_df[(remaining_df['POSno'] == \"['PRON']\") | \n",
    "                    (remaining_df['mention'].str.contains(pron_clit_formes, na=False))]\n",
    "\n",
    "# Drop identified rows from remaining_df\n",
    "remaining_df = remaining_df.drop(pron.index)\n",
    "\n",
    "\n",
    "det_poss = remaining_df[(remaining_df['POSno'] == \"['DET']\") & remaining_df['morphNoPunct'].str.contains('Poss=Yes', na=False)]\n",
    "remaining_df = remaining_df.drop(det_poss.index)\n",
    "\n",
    "\n",
    "num = remaining_df[(remaining_df['POSno'].str.startswith(\"['NUM'\", na=False))]\n",
    "remaining_df = remaining_df.drop(num.index)\n",
    "\n",
    "sn_no_det = remaining_df[remaining_df['POSno'].str.contains('NOUN', na=False) & ~remaining_df['POSno'].str.startswith(\"['DET\", na=False)]\n",
    "remaining_df = remaining_df.drop(sn_no_det.index)\n",
    "\n",
    "\n",
    "# Collect remaining elements into \"autre\"\n",
    "autre = remaining_df.copy()\n",
    "\n",
    "# Write to Excel\n",
    "with pd.ExcelWriter('ita_types.xlsx') as writer:\n",
    "    sn_def.to_excel(writer, sheet_name='sn_def', index=False)\n",
    "    sn_ind.to_excel(writer, sheet_name='sn_indef', index=False)\n",
    "    sn_poss.to_excel(writer, sheet_name='sn_poss', index=False)\n",
    "    verb.to_excel(writer, sheet_name='verb', index=False)\n",
    "    pron.to_excel(writer, sheet_name='pron', index=False)\n",
    "    propn.to_excel(writer, sheet_name='propn', index=False)\n",
    "    det_poss.to_excel(writer, sheet_name='det_poss', index=False)\n",
    "    sn_dem.to_excel(writer, sheet_name='sn_dem', index=False)\n",
    "    sn_no_det.to_excel(writer, sheet_name='sn_no_det', index=False)\n",
    "    num.to_excel(writer, sheet_name='numerals', index=False)\n",
    "    autre.to_excel(writer, sheet_name='autre', index=False)  # Write remaining elements\n",
    "    \n",
    "print(\"Excel file 'ita_types.xlsx' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed9065",
   "metadata": {},
   "source": [
    "calcul de la densité = nb mentions / nb tot tokens du texte\n",
    "TODO calcul de la densité nb TOKENS MENTIONS / nb tokens du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12617d7f",
   "metadata": {},
   "source": [
    "Calcolo dei tipi di menzione posto 1 e tipi di menzione posto 2 - da fare su file di categorizzazione delle menzioni per tipo già corretto manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea6d0c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-empty rows across all sheets: 4829\n",
      "   Sheet Name                 Type    Nb\n",
      "0      sn_def            SN défini  1250\n",
      "1    sn_indef          SN indéfini   397\n",
      "2     sn_poss         SN possessif   100\n",
      "3        verb        Anaphore Zéro  1473\n",
      "4        pron               Pronom   945\n",
      "5       propn           Nom Propre   323\n",
      "6    det_poss         SN possessif   208\n",
      "7      sn_dem      SN démonstratif    35\n",
      "8   sn_no_det  SN sans déterminant    56\n",
      "9    numerals                Autre     7\n",
      "10      autre                Autre    35\n",
      "                  Type    Nb\n",
      "0        Anaphore Zéro  1473\n",
      "1                Autre    42\n",
      "2           Nom Propre   323\n",
      "3               Pronom   945\n",
      "4            SN défini  1250\n",
      "5      SN démonstratif    35\n",
      "6          SN indéfini   397\n",
      "7         SN possessif   308\n",
      "8  SN sans déterminant    56\n",
      "4829\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = \"./annotations_francais/toutes_mentions_corpus_detail_interdistance_fr.csv\"\n",
    "#file = \"./annotations_italien/toutes_mentions_corpus_detail_interdistance_ita.csv\"\n",
    "\n",
    "\n",
    "# Define a mapping of sheet names to group names\n",
    "sheet_groups = {\n",
    "    \"sn_def\": \"SN défini\",\n",
    "    \"sn_indef\": \"SN indéfini\",\n",
    "    \"verb\": \"Anaphore Zéro\",\n",
    "    \"pron\": \"Pronom\",\n",
    "    \"propn\": \"Nom Propre\", \n",
    "    \"det_poss\": \"SN possessif\", \n",
    "    \"sn_poss\": \"SN possessif\",\n",
    "    \"sn_dem\" : \"SN démonstratif\",\n",
    "    \"sn_no_det\" : \"SN sans déterminant\",\n",
    "    \"numerals\" : \"Autre\",\n",
    "    \"autre\" : 'Autre'\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_ERType(file_path, sheet_groups, ment_order=None) :\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Dictionary to store dataframes\n",
    "    dfs = {}\n",
    "    \n",
    "    # Read each sheet into a dataframe\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        # Ensure 'Index' column exists\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            dfs[sheet_name] = df  # Store dataframe\n",
    "    \n",
    "    total_rows = sum(len(df.dropna(how=\"all\")) for df in dfs.values())\n",
    "    print(f\"Total number of non-empty rows across all sheets: {total_rows}\")\n",
    "    \n",
    "    # Create a list to store sheet names, groups, and row counts\n",
    "    sheet_info = []\n",
    "    \n",
    "    # Iterate through each sheet\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        \n",
    "        # Drop completely empty rows\n",
    "        df = df.dropna(how=\"all\")\n",
    "        \n",
    "        # If tag_value is provided, filter rows where 'tag' column matches the given value\n",
    "        if ment_order is not None and \"tag_occurrences\" in df.columns:\n",
    "            df = df[df[\"tag_occurrences\"] == ment_order]\n",
    "        \n",
    "        # Count rows excluding the header\n",
    "        row_count = len(df)\n",
    "        \n",
    "        # Determine the group (default to \"Uncategorized\" if not found in mapping)\n",
    "        group_name = sheet_groups.get(sheet_name, \"Uncategorized\")\n",
    "        \n",
    "        # Append sheet name, group, and row count to the list\n",
    "        sheet_info.append({\"Sheet Name\": sheet_name, \"Type\": group_name, \"Nb\": row_count})\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    sheet_info_df = pd.DataFrame(sheet_info)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(sheet_info_df)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    sheet_info_df = pd.DataFrame(sheet_info)\n",
    "    \n",
    "    # Now, group by 'Group' and sum the 'Row Count'\n",
    "    grouped_df = sheet_info_df.groupby(\"Type\")[\"Nb\"].sum().reset_index()\n",
    "    \n",
    "    # Display the grouped DataFrame\n",
    "    print(grouped_df)\n",
    "    return grouped_df\n",
    "\n",
    "# Load the Excel file - un foglio per tipologia di menzione\n",
    "#file_path_it = \"ita_types_v2.xlsx\"\n",
    "file_path_fr = \"typologie_mentions_fr_V3_DEF.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = calculate_ERType(file_path_it, sheet_groups)## --> filter out only chains\n",
    "\n",
    "sum_tout = df['Nb'].sum()\n",
    "print(sum_tout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CALCUL INTERDISTANCE - taux interdistance et moyenne par niveau/langue\n",
    "import pandas as pd\n",
    "\n",
    "#VF \n",
    "file = \"./toutes_mentions_corpus_detail_interdistance_fr.csv\"\n",
    "#VI\n",
    "#file = \"./toutes_mentions_corpus_detail_interdistance_ita.csv\"\n",
    "\n",
    "\n",
    "#file to pandas df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "#if existing, drop these cols\n",
    "# Define the columns to drop\n",
    "cols_to_drop = ['Unnamed: 0', 'Unnamed: 0.1']\n",
    "\n",
    "# Drop them if they exist\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "\n",
    "df = df.rename(columns={'Source': 'texte'})\n",
    "# GroupBy su 'texte' e 'tag' e applicazione delle operazioni richieste\n",
    "result = df.groupby(['texte', 'tag']).agg({\n",
    "    'tag_occurrences': 'max',         # Trova il valore massimo di 'occurrence'\n",
    "    'interdistance': 'sum',          # Somma i valori di 'interdistance'\n",
    "}).reset_index()\n",
    "\n",
    "#Filtrare solo le catene cioè tag_occurrences >= 3\n",
    "result = result[(result['tag_occurrences'] >= 3)]\n",
    "\n",
    "#taux interdistance\n",
    "# Aggiunta della nuova colonna con la divisione somma interdistanza / len chaine\n",
    "result['taux_interdistance'] = round(result['interdistance'] / result['tag_occurrences'],2)\n",
    "mean_tot1 = result['taux_interdistance'].mean()\n",
    "\n",
    "\n",
    "#risultato per ogni catena in csv\n",
    "result.to_csv(\"./corpus_francais_interdistance.csv\", \",\", encoding=\"utf-8\")\n",
    "\n",
    "#risultato per testo - media dei tassi ottenuti per ogni catena per testo\n",
    "# moyenne entre taux d'interdistance du même texte\n",
    "mean_interdistance = result.groupby('texte')['taux_interdistance'].mean().reset_index()\n",
    "mean_tot2 = result['taux_interdistance'].mean()\n",
    "\n",
    "##media per livello\n",
    "mean_ce1 = result.loc[result['texte'].str.contains('CE1', na=False), 'taux_interdistance'].mean()\n",
    "mean_ce2 = result.loc[result['texte'].str.contains('CE2', na=False), 'taux_interdistance'].mean()\n",
    "\n",
    "# filtered_CE1 = res.loc[res['texte'].str.contains('CE1', na=False), 'Characters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3d7103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Source  cat  cat+cat1  cat+cat1+cat2  cat+cat1+cat2+cat3  \\\n",
      "0     CE1-2015-102-D1-S212    6         0              0                   0   \n",
      "1     CE1-2015-102-D1-S217    0         0              0                   0   \n",
      "2     CE1-2015-104-D1-S824    6         0              0                   0   \n",
      "3     CE1-2015-104-D1-S841    9         0              0                   0   \n",
      "4    CE1-2015-108-D1-S2977    3         0              0                   0   \n",
      "..                     ...  ...       ...            ...                 ...   \n",
      "143   CE2-2016-96-D1-S1926   13         0              0                   0   \n",
      "144    CE2-2016-98-D1-S816    0         0              0                   0   \n",
      "145    CE2-2016-98-D1-S834    6         0              0                   0   \n",
      "146    CE2-2016-98-D1-S936    6         0              0                   0   \n",
      "147    CE2-2016-98-D1-S940    9         0              0                   0   \n",
      "\n",
      "     cat+ext1  cat+ext1+ext2  cat+ext2  cat+robot  cat+robot+witch+wolf  ...  \\\n",
      "0           0              0         0          0                     0  ...   \n",
      "1           0              0         0          0                     0  ...   \n",
      "2           0              0         0         11                     0  ...   \n",
      "3           0              0         0          0                     0  ...   \n",
      "4           5              0         0          0                     0  ...   \n",
      "..        ...            ...       ...        ...                   ...  ...   \n",
      "143         0              0         0          0                     0  ...   \n",
      "144         0              0         0          0                     0  ...   \n",
      "145         0              0         0          2                     0  ...   \n",
      "146         0              0         0          0                     0  ...   \n",
      "147         1              0         0          0                     0  ...   \n",
      "\n",
      "     witch  witch+witch1  witch+wolf  witch1  witch2  wolf  wolf+wolf1  wolf1  \\\n",
      "0        0             0           0       0       0     5           0      0   \n",
      "1        0             0           0       0       0     2           0      0   \n",
      "2        0             0           0       0       0     0           0      0   \n",
      "3       16             0           0       0       0     0           0      0   \n",
      "4        0             0           0       0       0     0           0      0   \n",
      "..     ...           ...         ...     ...     ...   ...         ...    ...   \n",
      "143     17             0           0       0       0     0           0      0   \n",
      "144      0             0           0       0       0    12           0      0   \n",
      "145      0             0           0       0       0     0           0      0   \n",
      "146      0             0           0       0       0     0           0      0   \n",
      "147      0             0           0       0       0     3           0      0   \n",
      "\n",
      "     Entities  Chains  \n",
      "0           2       2  \n",
      "1           3       2  \n",
      "2           4       3  \n",
      "3           4       3  \n",
      "4           4       4  \n",
      "..        ...     ...  \n",
      "143         6       5  \n",
      "144         8       2  \n",
      "145         3       2  \n",
      "146         2       2  \n",
      "147         4       2  \n",
      "\n",
      "[148 rows x 51 columns]\n",
      "Mean of Entities: 3.4121621621621623\n",
      "Mean of Chains: 2.310810810810811\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#calcul moyenne de personnage/entités par texte (entité sing et entités plurielles - séparé)\n",
    "#V1 - toute chaine\n",
    "#V2 - seulement coréf (>= 3)\n",
    "\n",
    "file = \"./annotations_italien/len_stats_ita.csv\"\n",
    "file = \"./annotations_francais/len_stats_fr.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Step 1: Count how many values are > 0 per row (excluding 'Source' column)\n",
    "df['Entities'] = (df.iloc[:, 1:] > 0).sum(axis=1)\n",
    "\n",
    "# Step 2: Compute the mean of 'Count_Positive'\n",
    "mean_positive = df['Entities'].mean()\n",
    "\n",
    "# Step 3: Count how many values are >= 3 per row\n",
    "df['Chains'] = (df.iloc[:, 1:-1] >= 3).sum(axis=1)\n",
    "\n",
    "# Step 4: Compute the mean of 'Count_GreaterEqual_3'\n",
    "mean_greater_equal_3 = df['Chains'].mean()\n",
    "\n",
    "# Print results\n",
    "print(df)\n",
    "print(f\"Mean of Entities: {mean_positive}\")\n",
    "print(f\"Mean of Chains: {mean_greater_equal_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ec3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#calcul moyenne de personnage/entités par texte (entité sing et entités plurielles - séparé)\n",
    "#V1 - toute chaine\n",
    "#V2 - seulement coréf (>= 3)\n",
    "\n",
    "ita_file = \"./annotations_italien/len_stats_ita.csv\"\n",
    "fr_file = \"./annotations_francais/len_stats_fr.csv\"\n",
    "\n",
    "df = pd.read_csv(ita_file)\n",
    "\n",
    "stop=col = 'wolf3'\n",
    "\n",
    "#print(df)\n",
    "#print(df.columns)\n",
    "\n",
    "def count_ints_gt_3(df, value_to_filter, stop_column):\n",
    "    # Step 1: Filter rows where 'Source' contains the value (e.g., 'CE1')\n",
    "    filtered_df = df[df['Source'].str.contains(value_to_filter, na=False)]\n",
    "    \n",
    "    # Step 2: Find the index of the 'Source' column and then get columns after it\n",
    "    source_index = df.columns.get_loc('Source')  # Get the position of 'Source'\n",
    "    columns_after_source = df.columns[source_index + 1 : ]  # Columns after 'Source'\n",
    "    \n",
    "    # Step 3: Select columns up until and including the stop column (among columns after 'Source')\n",
    "    column_index = df.columns.get_loc(stop_column) + 1\n",
    "    columns_up_to_stop = [col for col in columns_after_source if df.columns.get_loc(col) < column_index]\n",
    "    \n",
    "    filtered_df = filtered_df[columns_up_to_stop]\n",
    "    \n",
    "    # Step 4: Count how many values >= 3 in each row (only considering numeric columns)\n",
    "    count_gt_3 = (filtered_df >= 3).sum(axis=1)\n",
    "    \n",
    "    return count_gt_3\n",
    "\n",
    "ita_chains_CE1 = count_ints_gt_3(df, 'CE1', stop)\n",
    "print(len(ita_chains_CE1))\n",
    "ita_chains_CE2 = count_ints_gt_3(df, 'CE2', stop)\n",
    "print(len(ita_chains_CE2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09acd179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
